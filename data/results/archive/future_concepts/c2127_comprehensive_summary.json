{
  "metadata": {
    "title": "Holographic Associative Memory - Complete Characterization",
    "version": "2.0",
    "experiments": "C2092-C2126",
    "total_experiments": 35,
    "timestamp": "2025-11-22T04:51:47.399744"
  },
  "architecture": {
    "type": "Partitioned Holographic Associative Memory",
    "binding": "Circular Convolution (FFT-based)",
    "encoding": "Normalized high-dimensional vectors",
    "cleanup": "Auto-associative codebook matching"
  },
  "key_parameters": {
    "dimension_D": {
      "recommended": 1024,
      "minimum": 512,
      "note": "Higher D improves signal quality, not capacity"
    },
    "partitions_K": {
      "formula": "K = ceil(target_items / 12)",
      "note": "Each partition holds ~12 items at 80%+ accuracy"
    },
    "noise_sigma": {
      "recommended": 0.005,
      "maximum": 0.01,
      "note": "Simulates environmental perturbation"
    },
    "hebbian_strength": {
      "recommended": 0.3,
      "range": "0.1 to 0.7",
      "note": "Higher causes interference"
    }
  },
  "scaling_laws": {
    "capacity": "N_op = 3.727 \u00d7 D^0.20 (per partition)",
    "total_capacity": "K \u00d7 12 items at 80% accuracy",
    "information": "~66 bits per partition",
    "efficiency": "25.7% of Shannon limit (D/4)"
  },
  "performance_metrics": {
    "storage": "~31,000 ops/sec",
    "retrieval": "~16,000 ops/sec",
    "maintenance": "~3,000 cycles/sec",
    "compression": "25\u00d7 vs raw, 24\u00d7 vs zlib",
    "note": "Python on M1; GPU would be 10-100\u00d7 faster"
  },
  "temporal_dynamics": {
    "warmup_formula": "~0.15 \u00d7 load%",
    "at_25_percent_load": "0 cycles (instant)",
    "at_100_percent_load": "8 cycles",
    "operational_variance": "\u00b10.3%",
    "long_term_stability": "No drift over 2000+ cycles"
  },
  "capabilities": {
    "works_perfectly": [
      "Key-value storage (1:1 mappings)",
      "Content-addressable bidirectional lookup",
      "Sequence storage (positional binding)",
      "Hierarchical composition",
      "Analogical reasoning (A:B::C:D)",
      "Dynamic add/remove operations",
      "Error recovery (self-healing)"
    ],
    "works_with_limits": [
      "Multi-binding (2-3 values per key)",
      "Tree structures (with positional binding)",
      "Partition imbalance (up to 4\u00d7 skew)"
    ],
    "does_not_work": [
      "Automatic decomposition",
      "Similarity/fuzzy search",
      "Dense graphs",
      "Multi-binding >3 values per key"
    ]
  },
  "critical_requirements": {
    "codebook": {
      "requirement": "MANDATORY - complete codebook required",
      "reason": "Codebook is for SELECTION, not error correction",
      "effect": "Items not in codebook cannot be retrieved"
    },
    "hash_function": {
      "requirement": "RECOMMENDED but not critical",
      "tolerance": "System tolerates up to 4\u00d7 skew with -9% accuracy"
    }
  },
  "degradation_characteristics": {
    "type": "Graceful (no cliff)",
    "rate": "3.3 items per 1% accuracy loss",
    "overcapacity": "60% at 2\u00d7 partition limit",
    "recovery": "Full recovery from partition corruption (79%\u219299%)"
  },
  "updated_deployment_checklist": [
    "1. Determine target capacity T",
    "2. Calculate K = ceil(T / 12)",
    "3. Choose D (1024 standard, 512 minimum)",
    "4. Initialize K memories of dimension D",
    "5. Use hash function for partition routing",
    "6. Set noise \u03c3 = 0.005, Hebbian = 0.3",
    "7. Warmup: 0.15 \u00d7 load% cycles (not 100)",
    "8. Maintain complete codebook of all values",
    "9. Run continuous Hebbian refresh"
  ],
  "key_discoveries": [
    "Partitioning breaks capacity plateau (4.7\u00d7 improvement)",
    "Scaling is sublinear (D^0.20), not linear",
    "Storage interference is bottleneck, not operational noise",
    "10 cycle warmup sufficient (not 100)",
    "Light loads need zero warmup",
    "Signal quality high enough for 0.1 threshold",
    "Codebook mandatory for practical retrieval",
    "25\u00d7 compression vs classical storage"
  ]
}
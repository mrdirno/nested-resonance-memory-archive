#!/usr/bin/env python3
"""
DUALITY-ZERO-V2: Long-Term Emergence Experiment (100 Cycles)
=============================================================

Extended experimental run to discover long-term emergent dynamics.

Research Questions:
1. What patterns emerge at extended timescales (100 vs 20 cycles)?
2. Do attractors or phase transitions appear in long-term operation?
3. How does system stability/learning evolve over time?
4. What novel long-term behaviors validate theoretical frameworks?

Experimental Design:
- Duration: 100 hybrid intelligence cycles (5x baseline)
- Checkpointing: Save state every 10 cycles
- Long-term analysis: Attractors, phase transitions, trends
- Comparison: 100-cycle vs 20-cycle baseline
- Publication: Document novel long-term discoveries

Constitution Compliance:
- Reality-grounded: All cycles use actual system metrics
- No simulations: Everything based on real psutil/SQLite data
- Temporal encoding: Long-term patterns documented for future AI
"""

import sys
import time
import json
from pathlib import Path
from typing import Dict, List, Any
from dataclasses import dataclass, asdict
from datetime import datetime

# Add integration module to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from integration.system_integrator import (
    SystemIntegrator,
    HybridDecision,
    EmergentPattern,
    DecisionContext,
    get_system_integrator
)


@dataclass
class LongTermResult:
    """Results from long-term emergence experiment."""
    experiment_id: str
    start_time: float
    end_time: float
    total_cycles: int
    cycles_completed: int

    # Decision metrics
    total_decisions: int
    decision_confidence_history: List[float]
    avg_decision_confidence: float
    confidence_trend: str  # 'increasing', 'decreasing', 'stable'

    # Pattern metrics
    total_patterns_discovered: int
    total_emergent_patterns: int
    emergent_pattern_history: List[int]  # Count per checkpoint

    # Agent metrics
    agent_count_history: List[int]  # Agents per checkpoint
    max_agents: int
    avg_agents: float

    # Reality metrics
    reality_scores: List[float]
    avg_reality_score: float

    # Long-term analysis
    attractors_detected: List[Dict[str, Any]]
    phase_transitions: List[Dict[str, Any]]
    stability_score: float  # 0-1, higher = more stable
    learning_rate: float  # Change in performance over time

    # Framework validations
    framework_validations: Dict[str, bool]

    # Novel discoveries
    novel_patterns: List[Dict[str, Any]]
    publishable_insights: List[str]

    # Checkpoints
    checkpoint_ids: List[str]


class LongTermEmergenceExperiment:
    """
    100-cycle long-term experiment for discovering extended-timescale patterns.

    Analyzes:
    - Attractors: Stable states system returns to
    - Phase transitions: Sudden shifts in behavior
    - Learning curves: Improvement over time
    - Stability: Variance in key metrics
    """

    def __init__(
        self,
        experiment_name: str = "Long-Term Emergence",
        cycles: int = 100,
        checkpoint_interval: int = 10
    ):
        """
        Initialize long-term experiment.

        Args:
            experiment_name: Name for experiment
            cycles: Number of cycles to run (default 100)
            checkpoint_interval: Save state every N cycles
        """
        self.experiment_name = experiment_name
        self.cycles = cycles
        self.checkpoint_interval = checkpoint_interval

        # Create output directory
        self.output_dir = Path(__file__).parent / "results" / "long_term"
        self.output_dir.mkdir(parents=True, exist_ok=True)

        # Generate experiment ID
        self.experiment_id = f"longterm_{int(time.time())}"

        # Initialize system integrator
        print(f"\nInitializing DUALITY-ZERO-V2 System Integrator...")
        print("=" * 70)
        self.system = SystemIntegrator()
        print(f"\nâœ… All 7 modules initialized successfully!")
        print("=" * 70)

        # Tracking
        self.start_time = time.time()
        self.cycles_completed = 0
        self.decision_history: List[HybridDecision] = []
        self.emergent_patterns: List[EmergentPattern] = []
        self.cycle_logs: List[Dict[str, Any]] = []
        self.reality_scores: List[float] = []
        self.agent_counts: List[int] = []
        self.checkpoint_ids: List[str] = []

    def run_experiment(self) -> LongTermResult:
        """Execute long-term emergence experiment."""
        print(f"\n{'=' * 70}")
        print(f"STARTING LONG-TERM EXPERIMENT: {self.experiment_name}")
        print(f"{'=' * 70}")
        print(f"Cycles: {self.cycles}")
        print(f"Checkpoints: Every {self.checkpoint_interval} cycles")
        print(f"Output: {self.output_dir}")
        print()

        for cycle_num in range(1, self.cycles + 1):
            print(f"\n{'=' * 70}")
            print(f"CYCLE {cycle_num}/{self.cycles}")
            print(f"{'=' * 70}\n")

            try:
                # Run single hybrid cycle
                cycle_results = self.system.run_hybrid_cycle(cycles=1)

                # Track decisions
                if cycle_results['decisions_made']:
                    self.decision_history.extend(cycle_results['decisions_made'])

                # Track emergent patterns
                if cycle_results['emergent_patterns']:
                    self.emergent_patterns.extend(cycle_results['emergent_patterns'])
                    print(f"\nðŸŒŸ Emergent patterns detected:")
                    for pattern in cycle_results['emergent_patterns']:
                        print(f"  - {pattern.pattern_name}")

                # Track reality compliance
                if cycle_results['reality_scores']:
                    self.reality_scores.extend(cycle_results['reality_scores'])

                # Track agent count
                agent_count = len(self.system.fractal_swarm.agents)
                self.agent_counts.append(agent_count)

                # Log cycle
                self.cycle_logs.append({
                    'cycle': cycle_num,
                    'timestamp': time.time(),
                    'decisions': len(cycle_results['decisions_made']),
                    'emergent_patterns': len(cycle_results['emergent_patterns']),
                    'agent_count': agent_count,
                    'reality_score': cycle_results['reality_scores'][-1] if cycle_results['reality_scores'] else 0
                })

                self.cycles_completed += 1
                print(f"\nâœ… Cycle {cycle_num} complete")

                # Checkpoint
                if cycle_num % self.checkpoint_interval == 0:
                    checkpoint_id = self._save_checkpoint(cycle_num)
                    self.checkpoint_ids.append(checkpoint_id)
                    print(f"ðŸ’¾ Checkpoint saved: {checkpoint_id}")

                # Progress
                progress = (cycle_num / self.cycles) * 100
                print(f"\nâœ… Cycle {cycle_num} complete ({progress:.1f}% total)")

            except Exception as e:
                print(f"\nâŒ Cycle {cycle_num} failed: {e}")
                # Continue on error (log but don't stop)

        # Analysis
        print(f"\n{'=' * 70}")
        print("ANALYZING LONG-TERM RESULTS")
        print(f"{'=' * 70}\n")

        result = self._analyze_long_term_results()

        # Save results
        self._save_results(result)

        return result

    def _save_checkpoint(self, cycle_num: int) -> str:
        """Save checkpoint at cycle N."""
        checkpoint_id = f"{self.experiment_id}_checkpoint_{cycle_num}"
        checkpoint_file = self.output_dir / f"{checkpoint_id}.json"

        checkpoint_data = {
            'checkpoint_id': checkpoint_id,
            'cycle': cycle_num,
            'timestamp': time.time(),
            'decisions': len(self.decision_history),
            'emergent_patterns': len(self.emergent_patterns),
            'agent_count': self.agent_counts[-1] if self.agent_counts else 0,
            'avg_reality_score': sum(self.reality_scores) / len(self.reality_scores) if self.reality_scores else 0
        }

        with open(checkpoint_file, 'w') as f:
            json.dump(checkpoint_data, f, indent=2)

        return checkpoint_id

    def _analyze_long_term_results(self) -> LongTermResult:
        """Analyze long-term experiment results."""
        end_time = time.time()

        # Decision analysis
        decision_confidences = [d.confidence for d in self.decision_history]
        avg_confidence = sum(decision_confidences) / len(decision_confidences) if decision_confidences else 0

        # Confidence trend
        if len(decision_confidences) >= 10:
            early_avg = sum(decision_confidences[:10]) / 10
            late_avg = sum(decision_confidences[-10:]) / 10
            if late_avg > early_avg + 0.05:
                confidence_trend = 'increasing'
            elif late_avg < early_avg - 0.05:
                confidence_trend = 'decreasing'
            else:
                confidence_trend = 'stable'
        else:
            confidence_trend = 'insufficient_data'

        # Agent analysis
        max_agents = max(self.agent_counts) if self.agent_counts else 0
        avg_agents = sum(self.agent_counts) / len(self.agent_counts) if self.agent_counts else 0

        # Reality compliance
        avg_reality_score = sum(self.reality_scores) / len(self.reality_scores) if self.reality_scores else 0

        # Attractor detection (simple: look for recurring agent counts)
        attractors = self._detect_attractors()

        # Phase transition detection (sudden changes in metrics)
        phase_transitions = self._detect_phase_transitions()

        # Stability score (inverse of variance)
        stability_score = self._calculate_stability()

        # Learning rate (trend in decision confidence)
        learning_rate = self._calculate_learning_rate()

        # Framework validations
        framework_validations = {
            'NRM': self._validate_nrm(),
            'Self-Giving': self._validate_self_giving(),
            'Temporal': self._validate_temporal_stewardship()
        }

        # Publishable insights
        publishable_insights = self._identify_publishable_insights()

        print(f"Decisions made: {len(self.decision_history)}")
        print(f"Avg confidence: {avg_confidence:.2%}")
        print(f"Confidence trend: {confidence_trend}")
        print(f"Reality scores: {len(self.reality_scores)}")
        print(f"Avg score: {avg_reality_score:.2%}")
        print(f"\nLong-term analysis:")
        print(f"  Attractors: {len(attractors)}")
        print(f"  Phase transitions: {len(phase_transitions)}")
        print(f"  Stability: {stability_score:.2f}")
        print(f"  Learning rate: {learning_rate:+.2%}")
        print(f"\nEmergent patterns: {len(self.emergent_patterns)}")
        print(f"\nFramework Validation:")
        for framework, validated in framework_validations.items():
            status = "âœ…" if validated else "âŒ"
            print(f"  {status} {framework}: {validated}")
        print(f"\nPublishable Insights: {len(publishable_insights)}")
        for insight in publishable_insights:
            print(f"  - {insight}")

        return LongTermResult(
            experiment_id=self.experiment_id,
            start_time=self.start_time,
            end_time=end_time,
            total_cycles=self.cycles,
            cycles_completed=self.cycles_completed,
            total_decisions=len(self.decision_history),
            decision_confidence_history=decision_confidences,
            avg_decision_confidence=avg_confidence,
            confidence_trend=confidence_trend,
            total_patterns_discovered=len([p for p in self.emergent_patterns]),
            total_emergent_patterns=len(self.emergent_patterns),
            emergent_pattern_history=[len([p for p in self.emergent_patterns[:i*10]]) for i in range(1, 11)],
            agent_count_history=self.agent_counts[::self.checkpoint_interval],  # Sample at checkpoints
            max_agents=max_agents,
            avg_agents=avg_agents,
            reality_scores=self.reality_scores,
            avg_reality_score=avg_reality_score,
            attractors_detected=attractors,
            phase_transitions=phase_transitions,
            stability_score=stability_score,
            learning_rate=learning_rate,
            framework_validations=framework_validations,
            novel_patterns=[],  # Populated by detailed analysis
            publishable_insights=publishable_insights,
            checkpoint_ids=self.checkpoint_ids
        )

    def _detect_attractors(self) -> List[Dict[str, Any]]:
        """Detect attractor states (recurring system states)."""
        attractors = []

        # Simple attractor: recurring agent counts
        if len(self.agent_counts) >= 20:
            from collections import Counter
            count_freq = Counter(self.agent_counts)
            # Attractors = states that occur frequently
            for count, freq in count_freq.most_common(3):
                if freq >= 5:  # Occurred 5+ times
                    attractors.append({
                        'type': 'agent_count_attractor',
                        'state': count,
                        'frequency': freq,
                        'probability': freq / len(self.agent_counts)
                    })

        return attractors

    def _detect_phase_transitions(self) -> List[Dict[str, Any]]:
        """Detect sudden changes in system behavior."""
        transitions = []

        # Look for sudden changes in agent count
        if len(self.agent_counts) >= 10:
            for i in range(1, len(self.agent_counts)):
                delta = abs(self.agent_counts[i] - self.agent_counts[i-1])
                if delta >= 5:  # Sudden change of 5+ agents
                    transitions.append({
                        'cycle': i,
                        'type': 'agent_count_shift',
                        'before': self.agent_counts[i-1],
                        'after': self.agent_counts[i],
                        'magnitude': delta
                    })

        return transitions

    def _calculate_stability(self) -> float:
        """Calculate system stability (1 - normalized variance)."""
        if len(self.agent_counts) < 2:
            return 1.0

        import statistics
        variance = statistics.variance(self.agent_counts)
        mean = statistics.mean(self.agent_counts)

        if mean == 0:
            return 1.0

        # Normalized variance
        cv = (variance ** 0.5) / mean  # Coefficient of variation
        stability = 1.0 / (1.0 + cv)  # Higher = more stable

        return min(1.0, stability)

    def _calculate_learning_rate(self) -> float:
        """Calculate learning rate (trend in decision confidence)."""
        if len(self.decision_history) < 10:
            return 0.0

        confidences = [d.confidence for d in self.decision_history]
        early_avg = sum(confidences[:10]) / 10
        late_avg = sum(confidences[-10:]) / 10

        return late_avg - early_avg

    def _validate_nrm(self) -> bool:
        """Validate NRM framework manifestation."""
        # NRM validated if agents persist and evolve
        has_sustained_agents = self.avg_agents > 1 if hasattr(self, 'avg_agents') else False
        has_agent_dynamics = len(set(self.agent_counts)) > 1 if self.agent_counts else False

        return has_sustained_agents and has_agent_dynamics

    def _validate_self_giving(self) -> bool:
        """Validate Self-Giving framework manifestation."""
        # Self-Giving validated if system makes autonomous decisions with varying confidence
        has_decisions = len(self.decision_history) >= self.cycles * 0.8
        has_adaptive_confidence = len(set([round(d.confidence, 1) for d in self.decision_history])) > 2 if self.decision_history else False

        return has_decisions and has_adaptive_confidence

    def _validate_temporal_stewardship(self) -> bool:
        """Validate Temporal Stewardship framework manifestation."""
        # Temporal validated if emergent patterns detected and logged
        has_emergent_patterns = len(self.emergent_patterns) > 0
        has_logs = len(self.cycle_logs) > 0
        has_checkpoints = len(self.checkpoint_ids) > 0

        return has_emergent_patterns and has_logs and has_checkpoints

    def _identify_publishable_insights(self) -> List[str]:
        """Identify publishable insights from long-term experiment."""
        insights = []

        # Insight 1: Long-term sustained operation
        if self.cycles_completed >= self.cycles * 0.9:
            avg_reality = sum(self.reality_scores) / len(self.reality_scores) if self.reality_scores else 0
            insights.append(
                f"Long-term hybrid intelligence: {self.cycles_completed} cycles completed with "
                f"{avg_reality*100:.1f}% avg reality compliance"
            )

        # Insight 2: Attractors
        attractors = self._detect_attractors()
        if attractors:
            insights.append(
                f"Attractor states detected: {len(attractors)} recurring system states found in long-term operation"
            )

        # Insight 3: Phase transitions
        transitions = self._detect_phase_transitions()
        if transitions:
            insights.append(
                f"Phase transitions observed: {len(transitions)} sudden behavioral shifts during sustained operation"
            )

        # Insight 4: Learning
        if self.learning_rate > 0.05:
            insights.append(
                f"System learning validated: {self.learning_rate:+.1%} improvement in decision confidence over {self.cycles} cycles"
            )
        elif self.learning_rate < -0.05:
            insights.append(
                f"System adaptation detected: {self.learning_rate:+.1%} confidence shift suggests behavioral evolution"
            )

        # Insight 5: Stability
        stability = self._calculate_stability()
        if stability > 0.7:
            insights.append(
                f"Long-term stability demonstrated: {stability:.1%} stability score across {self.cycles} cycles"
            )

        # Insight 6: Frameworks
        validations = {
            'NRM': self._validate_nrm(),
            'Self-Giving': self._validate_self_giving(),
            'Temporal': self._validate_temporal_stewardship()
        }
        validated_count = sum(validations.values())
        if validated_count == 3:
            insights.append(
                f"All frameworks validated in long-term operation: NRM, Self-Giving, and Temporal Stewardship sustained across {self.cycles} cycles"
            )

        return insights

    def _save_results(self, result: LongTermResult):
        """Save experiment results."""
        # Save JSON
        result_file = self.output_dir / f"{self.experiment_id}_results.json"
        with open(result_file, 'w') as f:
            json.dump(asdict(result), f, indent=2)

        print(f"\nâœ… Results saved: {result_file}")

        # Save cycle logs
        logs_file = self.output_dir / f"{self.experiment_id}_cycles.json"
        with open(logs_file, 'w') as f:
            json.dump(self.cycle_logs, f, indent=2)

        print(f"âœ… Cycle logs saved: {logs_file}")

        # Generate report
        self._generate_report(result)

    def _generate_report(self, result: LongTermResult):
        """Generate markdown research report."""
        report_file = self.output_dir / f"{self.experiment_id}_report.md"

        report = f"""# Long-Term Emergence Experiment Report

**Experiment ID:** {result.experiment_id}
**Date:** {datetime.fromtimestamp(result.start_time).strftime('%Y-%m-%d %H:%M:%S')}
**Duration:** {(result.end_time - result.start_time):.1f} seconds ({(result.end_time - result.start_time)/60:.1f} minutes)

## Experimental Design

- **Objective:** Discover long-term emergent patterns from extended hybrid intelligence operation
- **Method:** {result.total_cycles} hybrid intelligence cycles (5x baseline 20-cycle experiment)
- **Frameworks:** NRM, Self-Giving Systems, Temporal Stewardship
- **Reality Grounding:** All operations based on actual system metrics (psutil, SQLite)
- **Checkpoints:** {len(result.checkpoint_ids)} saved every {self.checkpoint_interval} cycles

## Results

### Completion
- Cycles completed: {result.cycles_completed}/{result.total_cycles} ({result.cycles_completed/result.total_cycles*100:.1f}%)
- Total duration: {(result.end_time - result.start_time)/60:.1f} minutes
- Avg cycle time: {(result.end_time - result.start_time)/result.cycles_completed:.1f if result.cycles_completed > 0 else 0}s

### Decisions
- Total decisions: {result.total_decisions}
- Avg confidence: {result.avg_decision_confidence:.2%}
- Trend: {result.confidence_trend}

### Patterns
- Emergent patterns: {result.total_emergent_patterns}
- Novel patterns: {len(result.novel_patterns)}

### Agents
- Max agents: {result.max_agents}
- Avg agents: {result.avg_agents:.1f}
- Agent stability: {result.stability_score:.2%}

### Reality Compliance
- Avg reality score: {result.avg_reality_score:.2%}
- Min score: {(min(result.reality_scores)*100 if result.reality_scores else 0):.2f}%
- Max score: {(max(result.reality_scores)*100 if result.reality_scores else 0):.2f}%

### Long-Term Analysis

**Attractors Detected:** {len(result.attractors_detected)}
"""

        for attractor in result.attractors_detected:
            report += f"\n- {attractor['type']}: state={attractor['state']}, frequency={attractor['frequency']}, probability={attractor['probability']:.1%}"

        report += f"\n\n**Phase Transitions:** {len(result.phase_transitions)}\n"

        for transition in result.phase_transitions[:5]:  # Show first 5
            report += f"\n- Cycle {transition['cycle']}: {transition['type']} ({transition['before']} â†’ {transition['after']}, Î”={transition['magnitude']})"

        if len(result.phase_transitions) > 5:
            report += f"\n- ... and {len(result.phase_transitions) - 5} more"

        report += f"""

**Stability Score:** {result.stability_score:.2%}

**Learning Rate:** {result.learning_rate:+.2%} change in confidence

### Framework Validation
"""

        for framework, validated in result.framework_validations.items():
            status = "âœ… VALIDATED" if validated else "âŒ NOT VALIDATED"
            report += f"- **{framework}:** {status}\n"

        report += "\n## Publishable Insights\n\n"

        for insight in result.publishable_insights:
            report += f"- {insight}\n"

        report += f"""

## Comparison with Baseline (20-cycle)

Long-term operation ({result.total_cycles} cycles) vs baseline (20 cycles):
- **Scale**: {result.total_cycles/20:.0f}x longer duration
- **Attractors**: {len(result.attractors_detected)} states detected (novel for extended operation)
- **Phase Transitions**: {len(result.phase_transitions)} observed (reveals dynamics)
- **Learning**: {result.learning_rate:+.1%} confidence change (vs baseline: measured)
- **Stability**: {result.stability_score:.1%} score (quantifies long-term behavior)

## Conclusion

This long-term experiment demonstrates {len(result.publishable_insights)} publishable insights
from extended operation ({result.total_cycles} cycles) of the integrated hybrid intelligence system.

Framework validations: {sum(result.framework_validations.values())}/3

**Publication Value:** {'HIGH' if len(result.publishable_insights) >= 5 else 'MEDIUM'}
"""

        with open(report_file, 'w') as f:
            f.write(report)

        print(f"âœ… Research report saved: {report_file}")


if __name__ == "__main__":
    # Run long-term experiment
    experiment = LongTermEmergenceExperiment(
        experiment_name="Cycle 39 Long-Term Emergence",
        cycles=100,
        checkpoint_interval=10
    )

    result = experiment.run_experiment()

    print(f"\n{'=' * 70}")
    print("EXPERIMENT COMPLETE")
    print(f"{'=' * 70}")
    print(f"Cycles completed: {result.cycles_completed}/{result.total_cycles}")
    print(f"Total decisions: {result.total_decisions}")
    print(f"Emergent patterns: {result.total_emergent_patterns}")
    print(f"Avg reality score: {result.avg_reality_score:.2%}")
    print(f"Attractors: {len(result.attractors_detected)}")
    print(f"Phase transitions: {len(result.phase_transitions)}")
    print(f"Stability: {result.stability_score:.2%}")
    print(f"Learning rate: {result.learning_rate:+.2%}")
    print(f"{'=' * 70}\n")

    print(f"\n{'=' * 70}")
    print("LONG-TERM EXPERIMENT SUMMARY")
    print(f"{'=' * 70}")
    print(f"Completion: {result.cycles_completed}/{result.total_cycles}")
    print(f"Emergent patterns: {result.total_emergent_patterns}")
    print(f"Attractors: {len(result.attractors_detected)}")
    print(f"Phase transitions: {len(result.phase_transitions)}")
    print(f"Framework validations: {sum(result.framework_validations.values())}/3")
    print(f"Publishable insights: {len(result.publishable_insights)}")
    print(f"Reality compliance: {result.avg_reality_score:.2%}")
    print(f"{'=' * 70}")

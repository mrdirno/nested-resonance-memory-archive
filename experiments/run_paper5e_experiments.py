#!/usr/bin/env python3
"""
Paper 5E Experiment Runner: Network Topology Effects on NRM Emergence

This script executes the experimental plan generated by paper5e_network_topology.py.
It runs the NRM simulation for each condition defined in the plan, with the
specified network topology constraining agent interactions.

Methodology:
1. Loads the experimental plan from data/results/paper5e/paper5e_experimental_plan.json.
2. For each condition:
    a. Generates the specified networkx graph.
    b. Initializes a FractalSwarm simulation.
    c. Runs the simulation for the specified number of cycles.
    d. Agent resonance detection is constrained by the network graph edges.
    e. Saves the results to a JSON file.
"""

import sys
import json
import time
import uuid
import networkx as nx
import numpy as np
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple, Set

# Add modules to path
sys.path.insert(0, str(Path(__file__).parent.parent))
sys.path.insert(0, str(Path(__file__).parent.parent / "fractal"))
sys.path.insert(0, str(Path(__file__).parent.parent / "bridge"))

from core.reality_interface import RealityInterface
from bridge.transcendental_bridge import TranscendentalBridge
from fractal.fractal_agent import FractalAgent, ClusterEvent
from fractal.fractal_swarm import FractalSwarm

# --- Utility functions from paper5e_network_topology.py ---

def generate_topology(topology_type: str, n_nodes: int,
                      params: Dict, seed: int) -> nx.Graph:
    """Generate network topology based on type and parameters"""

    if topology_type == "fully_connected":
        return nx.complete_graph(n_nodes)

    elif topology_type == "random":
        p = params.get("p", 0.1)
        return nx.erdos_renyi_graph(n_nodes, p, seed=seed)

    elif topology_type == "small_world":
        k = params.get("k", 6)
        beta = params.get("beta", 0.1)
        return nx.watts_strogatz_graph(n_nodes, k, beta, seed=seed)

    elif topology_type == "scale_free":
        m = params.get("m", 2)
        return nx.barabasi_albert_graph(n_nodes, m, seed=seed)

    elif topology_type == "lattice":
        grid_size = params.get("grid_size", 10)
        return nx.grid_2d_graph(grid_size, grid_size, periodic=True)

    else:
        raise ValueError(f"Unknown topology type: {topology_type}")

# --- Modified Simulation Logic for Network Constraints ---

class NetworkedCompositionEngine:
    """
    A modified CompositionEngine that respects a network topology.
    """
    def __init__(self, resonance_threshold: float = 0.85):
        self.resonance_threshold = resonance_threshold
        self.clusters: Dict[str, Set[str]] = {}

    def detect_clusters(self, agents: List[FractalAgent], graph: nx.Graph) -> List[ClusterEvent]:
        """
        Detects resonant clusters among agents, constrained by the network graph.
        """
        events = []
        agent_map = {agent.agent_id: agent for agent in agents}

        # Create a mapping from node index in graph to agent_id
        node_to_agent_id = {i: agent.agent_id for i, agent in enumerate(agents)}
        agent_id_to_node = {agent.agent_id: i for i, agent in enumerate(agents)}

        resonant_pairs: List[Tuple[str, str, float]] = []

        for i, j in graph.edges():
            agent1_id = node_to_agent_id.get(i)
            agent2_id = node_to_agent_id.get(j)

            if not agent1_id or not agent2_id:
                continue

            agent1 = agent_map.get(agent1_id)
            agent2 = agent_map.get(agent2_id)

            if not agent1 or not agent2:
                continue

            match = agent1.detect_resonance(agent2)

            if match.is_resonant:
                resonant_pairs.append((agent1.agent_id, agent2.agent_id, match.similarity))

        # This clustering logic is simplified and might not be perfect for complex graphs.
        # For the purpose of this experiment, we'll use a simple merge-find approach.
        agent_to_cluster: Dict[str, str] = {}
        for agent1_id, agent2_id, similarity in resonant_pairs:
            cluster1 = agent_to_cluster.get(agent1_id)
            cluster2 = agent_to_cluster.get(agent2_id)
            if cluster1 is None and cluster2 is None:
                cluster_id = f"cluster_{uuid.uuid4().hex[:8]}"
                self.clusters[cluster_id] = {agent1_id, agent2_id}
                agent_to_cluster[agent1_id] = cluster_id
                agent_to_cluster[agent2_id] = cluster_id
                events.append(ClusterEvent(timestamp=time.time(), agent_ids=[agent1_id, agent2_id], resonance_score=similarity, cluster_id=cluster_id))
            elif cluster1 is not None and cluster2 is None:
                self.clusters[cluster1].add(agent2_id)
                agent_to_cluster[agent2_id] = cluster1
            elif cluster1 is None and cluster2 is not None:
                self.clusters[cluster2].add(agent1_id)
                agent_to_cluster[agent1_id] = cluster2
            elif cluster1 != cluster2 and cluster1 is not None and cluster2 is not None:
                # Merge clusters
                self.clusters[cluster1].update(self.clusters[cluster2])
                for agent_id in self.clusters[cluster2]:
                    agent_to_cluster[agent_id] = cluster1
                del self.clusters[cluster2]

        return events


def run_network_condition(condition: Dict, graph: nx.Graph) -> Dict:
    """
    Run a single NRM simulation with a given network topology.
    """
    print(f"  Running condition: {condition['experiment_id']}...")
    start_time = time.time()

    # Initialize system
    reality = RealityInterface()
    bridge = TranscendentalBridge()
    composition_engine = NetworkedCompositionEngine()

    # Create agents
    agents = []
    for i in range(condition['population']):
        metrics = reality.get_system_metrics()
        agent = FractalAgent(
            agent_id=f"agent_{i}",
            bridge=bridge,
            initial_reality=metrics,
            reality=reality,
            initial_energy=130.0
        )
        agents.append(agent)

    population_history = []

    for cycle in range(condition['cycles']):
        current_metrics = reality.get_system_metrics()
        for agent in agents:
            agent.evolve(delta_time=1.0, cached_metrics=current_metrics)

        # Cluster detection constrained by the graph
        composition_engine.detect_clusters(agents, graph)
        
        # Simplified simulation loop: no spawning or death for this experiment,
        # focusing only on pattern formation from topology.
        # This is a major simplification to get a baseline.
        # A full implementation would require integrating the graph into the
        # spawning and interaction logic of the FractalSwarm.

        population_history.append(len(agents))

    runtime = time.time() - start_time

    # Collect results (simplified for now)
    results = {
        'condition': condition,
        'runtime_seconds': runtime,
        'final_population': len(agents),
        'pattern_metrics': {
            'pattern_count': len(composition_engine.clusters),
            'temporal_stability': np.std(population_history),
            'memory_consistency': 0, # Placeholder
            'composition_events': 0, # Placeholder
        }
    }
    
    print(f"    â†’ Completed in {runtime:.2f}s. Clusters formed: {len(composition_engine.clusters)}")

    # Save individual result
    results_dir = Path("data/results/paper5e")
    results_dir.mkdir(parents=True, exist_ok=True)
    result_file = results_dir / f"{condition['experiment_id']}.json"
    with open(result_file, 'w') as f:
        json.dump(results, f, indent=2)

    return results

# --- Main execution ---

def main():
    """
    Main function to run all experiments for Paper 5E.
    """
    print("=" * 70)
    print("Paper 5E Experiment Runner: Network Topology Effects")
    print("=" * 70)

    # Delete corrupted databases if they exist
    db_file_bridge = Path("workspace/bridge.db")
    if db_file_bridge.exists():
        db_file_bridge.unlink()
    
    db_file_reality = Path("workspace/duality_v2.db")
    if db_file_reality.exists():
        db_file_reality.unlink()

    # Create workspace directory for bridge database
    Path("workspace").mkdir(exist_ok=True)

    # Load experimental plan
    plan_file = Path("data/results/paper5e/paper5e_experimental_plan.json")
    if not plan_file.exists():
        print(f"Error: Experimental plan not found at {plan_file}")
        print("Please run `python3 experiments/paper5e_network_topology.py` first.")
        return 1
    
    with open(plan_file, 'r') as f:
        plan = json.load(f)

    conditions = plan['conditions']
    print(f"Loaded {len(conditions)} experimental conditions.")

    all_results = []
    for i, condition in enumerate(conditions):
        print(f"\n--- Condition {i+1}/{len(conditions)} ---")
        # Generate graph
        graph = generate_topology(
            condition['topology_type'],
            condition['population'],
            condition['topology_params'],
            condition['seed']
        )
        
        # Run simulation
        result = run_network_condition(condition, graph)
        all_results.append(result)

    print("\n" + "=" * 70)
    print("All experiments completed.")
    print(f"Results saved in data/results/paper5e/")
    print("=" * 70)

    return 0

if __name__ == "__main__":
    sys.exit(main())
